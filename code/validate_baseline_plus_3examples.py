"""
Baseline + 3 Examples Train ê²€ì¦

ëª©í‘œ:
- baseline_plus_3examples í”„ë¡¬í”„íŠ¸ ê²€ì¦
- RuleChecklist í›„ì²˜ë¦¬ ì‚¬ìš© (ì•ˆì „)
- Train 254ê°œ í‰ê°€
- ëª©í‘œ: Recall 32-33% (ê¸°ì¡´ 32.24% ìœ ì§€ ë˜ëŠ” ì†Œí­ ìƒìŠ¹)
"""

import pandas as pd
import json
import re
from pathlib import Path
from src.generator import SentenceGenerator
from src.evaluator import Evaluator


def validate_baseline_plus_3examples():
    """
    Baseline + 3 Examples Train ê²€ì¦
    """
    print("="*70)
    print("Baseline + 3 Examples Train ê²€ì¦")
    print("="*70)
    print()

    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(Path(__file__).parent / "data" / "train.csv")

    print(f"ì´ ìƒ˜í”Œ: {len(train_df)}ê°œ")
    print()

    # Generator ì´ˆê¸°í™”
    print("í”„ë¡¬í”„íŠ¸: baseline_plus_3examples")
    print("í›„ì²˜ë¦¬: RuleChecklist (ì•ˆì „)")
    print()

    generator = SentenceGenerator(
        prompt_name='baseline_plus_3examples',
        enable_postprocessing=True,
        use_enhanced_postprocessor=False  # RuleChecklist ì‚¬ìš©
    )

    # êµì • ì‹¤í–‰
    print(f"êµì • ì§„í–‰ ì¤‘... (API í˜¸ì¶œ {len(train_df)}íšŒ, ì˜ˆìƒ ì‹œê°„: 10-15ë¶„)")
    corrections = []

    for idx, row in train_df.iterrows():
        err_text = row['err_sentence']

        # API í˜¸ì¶œ
        corrected = generator.generate_single(err_text)

        corrections.append({
            'index': idx,
            'type': row['type'],
            'err_sentence': err_text,
            'cor_sentence_gold': row['cor_sentence'],
            'cor_sentence_pred': corrected,
            'original_target_part': row['original_target_part'],
            'golden_target_part': row['golden_target_part']
        })

        # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë§¤ 25ê°œë§ˆë‹¤)
        if len(corrections) % 25 == 0:
            print(f"  [{len(corrections)}/{len(train_df)}] ì™„ë£Œ... ({len(corrections)/len(train_df)*100:.1f}%)")

    print(f"  [{len(corrections)}/{len(train_df)}] ì™„ë£Œ! (100.0%)")

    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(corrections)

    # í‰ê°€
    print("\ní‰ê°€ ì¤‘...")

    # ì •ë‹µê³¼ ì˜ˆì¸¡ ë°ì´í„°í”„ë ˆì„ ì¤€ë¹„
    true_df = train_df[['err_sentence', 'cor_sentence', 'original_target_part', 'golden_target_part']].reset_index(drop=True)
    pred_df = results_df[['err_sentence', 'cor_sentence_pred']].rename(columns={'cor_sentence_pred': 'cor_sentence'}).reset_index(drop=True)

    # Evaluatorë¡œ í‰ê°€
    evaluator = Evaluator()
    eval_result = evaluator.evaluate(true_df, pred_df)

    # ë©”íŠ¸ë¦­ ì¶”ì¶œ
    recall = eval_result.get('recall', 0.0)
    precision = eval_result.get('precision', 0.0)

    # ì¶”ê°€ ì§€í‘œ
    def calc_target_rate():
        def check_target(row):
            golden = row['golden_target_part']
            pred = row['cor_sentence_pred']
            if pd.notna(golden) and pd.notna(pred) and golden in str(pred):
                return True
            return False

        success = results_df.apply(check_target, axis=1).sum()
        total = results_df[results_df['golden_target_part'].notna()].shape[0]
        rate = success / total * 100 if total > 0 else 0
        return success, total, rate

    target_success, target_total, target_rate = calc_target_rate()

    # ë©”íƒ€ë°ì´í„° ì²´í¬
    def detect_metadata(text):
        if pd.isna(text):
            return False
        patterns = [r'ì›ë¬¸:', r'êµì •:', r'<ì›ë¬¸>', r'<êµì •>', r'\[ìµœì¢…', r'â€»', r'#']
        for pattern in patterns:
            if re.search(pattern, text):
                return True
        return False

    metadata_count = results_df['cor_sentence_pred'].apply(detect_metadata).sum()

    # ê¸¸ì´ í­ë°œ ì²´í¬
    results_df['length_ratio'] = results_df.apply(
        lambda row: len(row['cor_sentence_pred']) / len(row['err_sentence'])
        if len(row['err_sentence']) > 0 else 1.0,
        axis=1
    )
    length_explosion_count = len(results_df[results_df['length_ratio'] > 1.5])

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("ê²€ì¦ ê²°ê³¼")
    print("="*70)
    print(f"Recall: {recall:.2f}%")
    print(f"Precision: {precision:.2f}%")
    print(f"íƒ€ê¹ƒ êµì •: {target_success}/{target_total} ({target_rate:.1f}%)")
    print(f"ë©”íƒ€ë°ì´í„°: {metadata_count}ê°œ ({metadata_count/len(train_df)*100:.1f}%)")
    print(f"ê¸¸ì´ í­ë°œ (>150%): {length_explosion_count}ê°œ")
    print()

    # ë¹„êµ
    print("="*70)
    print("ë¹„êµ")
    print("="*70)
    print()
    print("ê¸°ì¡´ Baseline (ê²€ì¦ë¨):")
    print("  Train Recall: 32.24%")
    print("  Public LB: 34.04%")
    print()
    print(f"Baseline + 3 Examples:")
    print(f"  Train Recall: {recall:.2f}%")
    print(f"  ì°¨ì´: {recall - 32.24:+.2f}%p")
    print()

    # íŒì •
    print("="*70)
    print("íŒì •")
    print("="*70)
    print()

    success = True

    if recall >= 32:
        print(f"âœ… Recall {recall:.2f}% (ëª©í‘œ: â‰¥32%)")
    else:
        print(f"âŒ Recall {recall:.2f}% (ëª©í‘œ: â‰¥32%)")
        success = False

    if metadata_count <= 10:
        print(f"âœ… ë©”íƒ€ë°ì´í„° {metadata_count}ê°œ (ëª©í‘œ: â‰¤10ê°œ)")
    else:
        print(f"âš ï¸ ë©”íƒ€ë°ì´í„° {metadata_count}ê°œ (ëª©í‘œ: â‰¤10ê°œ)")

    if length_explosion_count <= 10:
        print(f"âœ… ê¸¸ì´ í­ë°œ {length_explosion_count}ê°œ (ëª©í‘œ: â‰¤10ê°œ)")
    else:
        print(f"âš ï¸ ê¸¸ì´ í­ë°œ {length_explosion_count}ê°œ (ëª©í‘œ: â‰¤10ê°œ)")

    print()

    if success:
        print("ğŸ¯ ê²€ì¦ í†µê³¼!")
        print("   â†’ Phase 3 íšŒê·€ í…ŒìŠ¤íŠ¸ë¡œ ì§„í–‰")
    else:
        print("âŒ ê²€ì¦ ì‹¤íŒ¨")
        print("   â†’ í”„ë¡¬í”„íŠ¸ ì¬ì¡°ì • í•„ìš”")

    print()

    # ê²°ê³¼ ì €ì¥
    output_dir = Path(__file__).parent / "outputs" / "experiments"
    output_dir.mkdir(parents=True, exist_ok=True)

    results_df.to_csv(
        output_dir / "baseline_plus_3examples_train_results.csv",
        index=False,
        encoding='utf-8'
    )

    metrics = {
        'recall': recall,
        'precision': precision,
        'target_success_rate': target_rate,
        'metadata_count': int(metadata_count),
        'length_explosion_count': length_explosion_count
    }

    with open(output_dir / "baseline_plus_3examples_train_metrics.json", 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)

    print(f"ê²°ê³¼ ì €ì¥:")
    print(f"  - {output_dir / 'baseline_plus_3examples_train_results.csv'}")
    print(f"  - {output_dir / 'baseline_plus_3examples_train_metrics.json'}")
    print()

    return metrics, results_df, success


if __name__ == "__main__":
    metrics, results_df, success = validate_baseline_plus_3examples()

    if success:
        print("ë‹¤ìŒ ë‹¨ê³„: Phase 3 íšŒê·€ í…ŒìŠ¤íŠ¸ (62ê°œ)")
    else:
        print("ë‹¤ìŒ ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ì¬ì¡°ì •")
