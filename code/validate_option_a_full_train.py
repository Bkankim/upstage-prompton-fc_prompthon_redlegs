"""
Phase 5: Train ì „ì²´(254ê°œ) í‰ê°€ - Option A

ëª©í‘œ:
- Option A (fewshot_v3 + Enhanced í›„ì²˜ë¦¬) ìµœì¢… ì„±ëŠ¥ í™•ì •
- ì·¨ì•½ ìœ í˜• (ë°›ì¹¨ì—ë”°ë¥¸, ì‚¬ì´ì‹œì˜·) ì¶”ì 
- ë©”íƒ€ë°ì´í„° ë°œìƒ ì¼€ì´ìŠ¤ ìˆ˜ë™ ê²€í† 
"""

import pandas as pd
import json
import re
from pathlib import Path
from src.generator import SentenceGenerator
from src.evaluator import Evaluator


def calculate_additional_metrics(results_df):
    """
    ì¶”ê°€ í‰ê°€ ì§€í‘œ ê³„ì‚°
    """
    # íƒ€ê¹ƒ êµì • ì„±ê³µë¥ 
    def check_target_correction(row):
        golden_target = row['golden_target_part']
        pred = row['cor_sentence_pred']
        if pd.notna(golden_target) and pd.notna(pred) and golden_target in str(pred):
            return True
        return False

    target_success = results_df.apply(check_target_correction, axis=1).sum()
    target_total = results_df[results_df['golden_target_part'].notna()].shape[0]
    target_success_rate = target_success / target_total * 100 if target_total > 0 else 0

    # ë©”íƒ€ë°ì´í„° ë°œìƒë¥  (ìë™ íƒì§€)
    def detect_metadata(text):
        if pd.isna(text):
            return False
        metadata_patterns = [
            r'â€»', r'ì§€ì‹œì‚¬í•­', r'ì„¤ëª…', r'ì°¸ê³ ',
            r'ì›ë¬¸:', r'êµì •:', r'ìˆ˜ì •:', r'ê²°ê³¼:',
            r'<ì›ë¬¸>', r'<êµì •>',
            r'\[ìµœì¢…', r'\[ì¬ìµœì¢…', r'\[ì‹œìŠ¤í…œ',
            r'ê·œì¹™.*ë”°ë¼', r'ì¶”ê°€.*ì§€ì‹œ'
        ]
        for pattern in metadata_patterns:
            if re.search(pattern, text):
                return True
        return False

    metadata_count = results_df['cor_sentence_pred'].apply(detect_metadata).sum()
    metadata_rate = metadata_count / len(results_df) * 100

    # í‰ê·  ê¸¸ì´ ë³€í™”
    def calculate_length_ratio(row):
        err_len = len(row['err_sentence'])
        pred_len = len(row['cor_sentence_pred'])
        return pred_len / err_len if err_len > 0 else 0

    length_ratios = results_df.apply(calculate_length_ratio, axis=1)
    avg_length_ratio = length_ratios.mean() * 100

    # ê¸¸ì´ í­ë°œ ì¼€ì´ìŠ¤ (150% ì´ˆê³¼)
    length_explosion_cases = results_df[length_ratios > 1.5]

    return {
        'target_success_count': int(target_success),
        'target_total_count': int(target_total),
        'target_success_rate': float(target_success_rate),
        'metadata_count': int(metadata_count),
        'metadata_rate': float(metadata_rate),
        'avg_length_ratio': float(avg_length_ratio),
        'length_explosion_count': len(length_explosion_cases),
        'length_explosion_indices': length_explosion_cases['index'].tolist() if len(length_explosion_cases) > 0 else []
    }


def validate_full_train():
    """
    Train ì „ì²´(254ê°œ) í‰ê°€ ì‹¤í–‰
    """
    print("="*70)
    print("Phase 5: Train ì „ì²´(254ê°œ) Option A ìµœì¢… í‰ê°€")
    print("="*70)

    # ë°ì´í„° ë¡œë“œ
    train_df = pd.read_csv(Path(__file__).parent / "data" / "train.csv")

    print(f"\nì´ ìƒ˜í”Œ: {len(train_df)}ê°œ")
    print("\nìœ í˜•ë³„ ë¶„í¬:")
    print(train_df['type'].value_counts().sort_index())

    # Generator ì´ˆê¸°í™”
    print("\ní”„ë¡¬í”„íŠ¸: fewshot_v3")
    print("í›„ì²˜ë¦¬: EnhancedPostprocessor")

    generator = SentenceGenerator(
        prompt_name='fewshot_v3',
        enable_postprocessing=True,
        use_enhanced_postprocessor=True
    )

    # êµì • ì‹¤í–‰
    print(f"\nêµì • ì§„í–‰ ì¤‘... (API í˜¸ì¶œ {len(train_df)}íšŒ, ì˜ˆìƒ ì‹œê°„: 10-15ë¶„)")
    corrections = []

    for idx, row in train_df.iterrows():
        err_text = row['err_sentence']

        # API í˜¸ì¶œ
        corrected = generator.generate_single(err_text)

        corrections.append({
            'index': idx,
            'type': row['type'],
            'err_sentence': err_text,
            'cor_sentence_gold': row['cor_sentence'],
            'cor_sentence_pred': corrected,
            'original_target_part': row['original_target_part'],
            'golden_target_part': row['golden_target_part']
        })

        # ì§„í–‰ ìƒí™© ì¶œë ¥ (ë§¤ 25ê°œë§ˆë‹¤)
        if len(corrections) % 25 == 0:
            print(f"  [{len(corrections)}/{len(train_df)}] ì™„ë£Œ... ({len(corrections)/len(train_df)*100:.1f}%)")

    print(f"  [{len(corrections)}/{len(train_df)}] ì™„ë£Œ! (100.0%)")

    # DataFrame ë³€í™˜
    results_df = pd.DataFrame(corrections)

    # í‰ê°€
    print("\ní‰ê°€ ì¤‘...")

    # ì •ë‹µê³¼ ì˜ˆì¸¡ ë°ì´í„°í”„ë ˆì„ ì¤€ë¹„
    true_df = train_df[['err_sentence', 'cor_sentence', 'original_target_part', 'golden_target_part']].reset_index(drop=True)
    pred_df = results_df[['err_sentence', 'cor_sentence_pred']].rename(columns={'cor_sentence_pred': 'cor_sentence'}).reset_index(drop=True)

    # Evaluatorë¡œ í‰ê°€
    evaluator = Evaluator()
    eval_result = evaluator.evaluate(true_df, pred_df)

    # ë©”íŠ¸ë¦­ ì¶”ì¶œ
    recall = eval_result.get('recall', 0.0)
    precision = eval_result.get('precision', 0.0)

    # ì¶”ê°€ ì§€í‘œ ê³„ì‚°
    additional_metrics = calculate_additional_metrics(results_df)

    # í†µí•© ë©”íŠ¸ë¦­
    metrics = {
        'recall': recall,
        'precision': precision,
        'sample_count': len(train_df),
        **additional_metrics
    }

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*70)
    print("Phase 5 ìµœì¢… í‰ê°€ ê²°ê³¼")
    print("="*70)
    print(f"Recall: {recall:.2f}%")
    print(f"Precision: {precision:.2f}%")
    print(f"ìƒ˜í”Œ ìˆ˜: {len(train_df)}ê°œ")
    print()
    print("ì¶”ê°€ ì§€í‘œ:")
    print(f"  íƒ€ê¹ƒ êµì • ì„±ê³µ: {additional_metrics['target_success_count']}/{additional_metrics['target_total_count']} ({additional_metrics['target_success_rate']:.1f}%)")
    print(f"  ë©”íƒ€ë°ì´í„° ì¶œí˜„ (ìë™ íƒì§€): {additional_metrics['metadata_count']}/{len(train_df)} ({additional_metrics['metadata_rate']:.1f}%)")
    print(f"  ê¸¸ì´ í­ë°œ ì¼€ì´ìŠ¤ (>150%): {additional_metrics['length_explosion_count']}ê°œ")
    print(f"  í‰ê·  ê¸¸ì´ ë¹„ìœ¨: {additional_metrics['avg_length_ratio']:.1f}%")

    # ë‹¨ê³„ë³„ ë¹„êµ
    print("\n" + "="*70)
    print("ë‹¨ê³„ë³„ ì„±ëŠ¥ ë¹„êµ")
    print("="*70)
    print()
    print("Phase 2 (18ê°œ ìƒ˜í”Œ):")
    print("  Recall: 42.11%")
    print("  íƒ€ê¹ƒ êµì •: 44.4%")
    print("  ë©”íƒ€ë°ì´í„°: 0.0%")
    print()
    print("Phase 3 (62ê°œ ìƒ˜í”Œ):")
    print("  Recall: 45.76%")
    print("  íƒ€ê¹ƒ êµì •: 50.0%")
    print("  ë©”íƒ€ë°ì´í„°: 1.6% (ì‹¤ì œ)")
    print()
    print(f"Phase 5 (254ê°œ ì „ì²´):")
    print(f"  Recall: {recall:.2f}%")
    print(f"  íƒ€ê¹ƒ êµì •: {additional_metrics['target_success_rate']:.1f}%")
    print(f"  ë©”íƒ€ë°ì´í„°: {additional_metrics['metadata_rate']:.1f}% (ìë™ íƒì§€)")
    print()

    # ìœ í˜•ë³„ ì„±ê³µë¥  ë¶„ì„
    print("="*70)
    print("ìœ í˜•ë³„ íƒ€ê¹ƒ êµì • ì„±ê³µë¥ ")
    print("="*70)
    print()

    type_success_rates = []
    for error_type in sorted(results_df['type'].unique()):
        type_results = results_df[results_df['type'] == error_type]
        type_target_total = type_results[type_results['golden_target_part'].notna()].shape[0]

        if type_target_total > 0:
            type_target_success = type_results.apply(
                lambda row: pd.notna(row['golden_target_part']) and
                            pd.notna(row['cor_sentence_pred']) and
                            row['golden_target_part'] in str(row['cor_sentence_pred']),
                axis=1
            ).sum()
            type_success_rate = type_target_success / type_target_total * 100
            type_success_rates.append({
                'type': error_type,
                'rate': float(type_success_rate),
                'success': int(type_target_success),
                'total': int(type_target_total)
            })
            print(f"  {error_type}: {type_target_success}/{type_target_total} ({type_success_rate:.1f}%)")

    # ì·¨ì•½ ìœ í˜• ì¬í™•ì¸
    if type_success_rates:
        success_rates_values = [item['rate'] for item in type_success_rates]
        mean_rate = sum(success_rates_values) / len(success_rates_values)
        std_rate = (sum((r - mean_rate) ** 2 for r in success_rates_values) / len(success_rates_values)) ** 0.5
        threshold = mean_rate - std_rate

        print()
        print(f"í‰ê·  ì„±ê³µë¥ : {mean_rate:.1f}%")
        print(f"í‘œì¤€í¸ì°¨: {std_rate:.1f}%")
        print(f"ì·¨ì•½ ìœ í˜• ê¸°ì¤€: < {threshold:.1f}% (í‰ê·  - 1Ïƒ)")
        print()

        weak_types = [
            item for item in type_success_rates
            if item['rate'] < threshold
        ]

        if weak_types:
            print("ì·¨ì•½ ìœ í˜•:")
            for item in weak_types:
                print(f"  {item['type']}: {item['success']}/{item['total']} ({item['rate']:.1f}%)")

            # Phase 3 ì·¨ì•½ ìœ í˜•ê³¼ ë¹„êµ
            phase3_weak = ['ë°›ì¹¨ì—ë”°ë¥¸', 'ì‚¬ì´ì‹œì˜·']
            print()
            print("Phase 3 ì·¨ì•½ ìœ í˜• ì¶”ì :")
            for weak_type in phase3_weak:
                matching = [item for item in type_success_rates if item['type'] == weak_type]
                if matching:
                    item = matching[0]
                    print(f"  {item['type']}: {item['success']}/{item['total']} ({item['rate']:.1f}%)")
                    if item['rate'] < threshold:
                        print(f"    â†’ ì—¬ì „íˆ ì·¨ì•½ âš ï¸")
                    else:
                        print(f"    â†’ ê°œì„ ë¨ âœ…")
        else:
            print("ì·¨ì•½ ìœ í˜• ì—†ìŒ (ëª¨ë“  ìœ í˜•ì´ í‰ê·  - 1Ïƒ ì´ìƒ)")

    print()

    # ìµœì¢… íŒì •
    print("="*70)
    print("ìµœì¢… íŒì •")
    print("="*70)
    print()

    if recall >= 40:
        print(f"âœ… Recall {recall:.2f}% ë‹¬ì„± (ëª©í‘œ: â‰¥ 40%)")
    else:
        print(f"âŒ Recall {recall:.2f}% ë¯¸ë‹¬ (ëª©í‘œ: â‰¥ 40%)")

    if additional_metrics['target_success_rate'] >= 45:
        print(f"âœ… íƒ€ê¹ƒ êµì • {additional_metrics['target_success_rate']:.1f}% ë‹¬ì„± (ëª©í‘œ: â‰¥ 45%)")
    else:
        print(f"âš ï¸ íƒ€ê¹ƒ êµì • {additional_metrics['target_success_rate']:.1f}% (ëª©í‘œ: â‰¥ 45%)")

    if additional_metrics['metadata_rate'] <= 5:
        print(f"âœ… ë©”íƒ€ë°ì´í„° {additional_metrics['metadata_rate']:.1f}% (ëª©í‘œ: â‰¤ 5%)")
    else:
        print(f"âš ï¸ ë©”íƒ€ë°ì´í„° {additional_metrics['metadata_rate']:.1f}% (ëª©í‘œ: â‰¤ 5%)")

    print()

    if recall >= 40 and additional_metrics['target_success_rate'] >= 45 and additional_metrics['metadata_rate'] <= 5:
        print("ğŸ¯ Option A ìµœì¢… í™•ì •!")
        print("   â†’ Phase 6: Test LB ì œì¶œ íŒŒì¼ ìƒì„±ìœ¼ë¡œ ì§„í–‰")
    else:
        print("âš ï¸ ì¼ë¶€ ëª©í‘œ ë¯¸ë‹¬")
        print("   â†’ ê²°ê³¼ ê²€í†  ë° ì¶”ê°€ ê°œì„  ê³ ë ¤")

    print()

    # ê²°ê³¼ ì €ì¥
    output_dir = Path(__file__).parent / "outputs" / "experiments"
    output_dir.mkdir(parents=True, exist_ok=True)

    # ìƒì„¸ ê²°ê³¼
    results_df.to_csv(
        output_dir / "phase5_full_train_results.csv",
        index=False,
        encoding='utf-8'
    )

    # ë©”íŠ¸ë¦­ ê²°ê³¼
    with open(output_dir / "phase5_full_train_metrics.json", 'w', encoding='utf-8') as f:
        json.dump({
            'sample_count': len(train_df),
            'metrics': metrics,
            'type_success_rates': type_success_rates,
            'weak_types': weak_types if weak_types else []
        }, f, ensure_ascii=False, indent=2)

    # ë©”íƒ€ë°ì´í„° ì¼€ì´ìŠ¤ ìˆ˜ë™ ê²€í† ìš©
    if additional_metrics['metadata_count'] > 0:
        metadata_cases = results_df[results_df['cor_sentence_pred'].apply(
            lambda x: any(re.search(pattern, str(x)) for pattern in [
                r'â€»', r'ì§€ì‹œì‚¬í•­', r'ì„¤ëª…', r'ì°¸ê³ ',
                r'ì›ë¬¸:', r'êµì •:', r'ìˆ˜ì •:', r'ê²°ê³¼:',
                r'<ì›ë¬¸>', r'<êµì •>',
                r'\[ìµœì¢…', r'\[ì¬ìµœì¢…', r'\[ì‹œìŠ¤í…œ',
                r'ê·œì¹™.*ë”°ë¼', r'ì¶”ê°€.*ì§€ì‹œ'
            ])
        )]

        metadata_cases.to_csv(
            output_dir / "phase5_metadata_cases_for_review.csv",
            index=False,
            encoding='utf-8'
        )
        print(f"ë©”íƒ€ë°ì´í„° ì˜ì‹¬ ì¼€ì´ìŠ¤: {output_dir / 'phase5_metadata_cases_for_review.csv'}")
        print("  â†’ ìˆ˜ë™ ê²€í†  ê¶Œì¥ (False Positive í™•ì¸)")
        print()

    # í›„ì²˜ë¦¬ ë¡œê·¸ ì €ì¥
    if hasattr(generator.postprocessor, 'save_processing_log'):
        log_path = Path(__file__).parent / "outputs" / "analysis" / "phase5_full_train_postprocess_log.json"
        log_path.parent.mkdir(parents=True, exist_ok=True)
        generator.postprocessor.save_processing_log(str(log_path))
        print(f"í›„ì²˜ë¦¬ ë¡œê·¸ ì €ì¥: {log_path}")

    print(f"\nê²°ê³¼ ì €ì¥ ì™„ë£Œ:")
    print(f"  - {output_dir / 'phase5_full_train_results.csv'}")
    print(f"  - {output_dir / 'phase5_full_train_metrics.json'}")

    return metrics, results_df


if __name__ == "__main__":
    metrics, results_df = validate_full_train()
