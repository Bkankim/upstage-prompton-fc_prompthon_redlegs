# 대회 정보

> Upstage Global Eval Challenge (GEC) - Promptathon

## 대회 개요

- **대회명**: Upstage GEC Promptathon
- **목표**: 프롬프트 엔지니어링만으로 한국어 문법 교정 성능 최대화
- **모델**: Upstage Solar Pro 2 (고정, 파인튜닝 불가)
- **기간**: 2024년 10월 ~ 진행 중
- **평가지표**: Recall (재현율)

---

## 제약사항

### API 제약

```yaml
세션 토큰 제한: 2000 토큰/세션
API 호출 제한: 최대 3회/케이스
일일 제출 제한: 20회 (KST 자정 리셋)
```

**의미**:
- Few-shot 예시를 많이 넣으면 토큰 초과
- 한 문장을 여러 번 재시도 불가 (최대 3회)
- 실험 전 신중한 계획 필요

### 데이터 제약

```yaml
외부 데이터 사용: 금지
RAG 사용: 내부 데이터(train.csv)만 허용
모델 변경: 불가 (Solar Pro 2 고정)
```

**전략**:
- Train 데이터 254개로 패턴 학습
- Few-shot 예시는 train.csv에서 추출
- 규칙 기반 후처리는 train.csv 분석 기반

---

## 데이터셋

### 구성

```
Train: 254개
Test:  109개
비율:  약 70:30
```

### 형식

```csv
id,err_sentence,cor_sentence,type
grm123456,"오류가 있는 문장","교정된 문장","맞춤법-맞춤법"
```

**컬럼**:
- `id`: 고유 식별자
- `err_sentence`: 오류 문장
- `cor_sentence`: 정답 교정 문장
- `type`: 오류 유형

### 오류 유형

| 유형 | Train 비율 | 예시 |
|------|-----------|------|
| 맞춤법-맞춤법 | 16.9% | 않 → 안, 찌게 → 찌개 |
| 문법-품사 | 11.0% | 갈려고 → 가려고 |
| 표준어비표준어 | 8.7% | 넘어지다 → 넘어지다 |
| 맞춤법-사이시옷 | 10.2% | 개나리꽃길 → 개나리꽃 길 |
| 문법-조사 | 7.5% | 탐탁치 → 탐탁지 |
| 띄어쓰기 | 6.7% | 받아봐야 → 받아 봐야 |
| 문장부호-문장부호 | 5.5% | (책) → 《책》 |
| 비문 | 5.1% | 문장 구조 수정 |
| 단순오탈자 | 4.3% | 오타 수정 |
| 기타 | 23.6% | 복합 오류, 분류 어려움 |

**특징**:
- 복합 오류 많음 (1개 문장에 여러 유형)
- 주관적 판단 필요 (비문, 표현 다듬기)
- 명확한 규칙 외 맥락 이해 중요

---

## 평가 방식

### Recall 계산

```
Recall = TP / (TP + FP + FN) × 100

TP: 정답과 예측이 일치하는 어절
FP: 예측에만 있는 어절 (잘못 추가)
FN: 정답에만 있는 어절 (놓침)
```

**예시**:
```
정답: "오늘 날씨가 안 좋은데"  (5 어절)
예측: "오늘 날씨가 매우 좋은데" (5 어절)

TP: 3 (오늘, 날씨가, 좋은데)
FP: 1 (매우)
FN: 1 (안)

Recall = 3 / (3 + 1 + 1) = 60%
```

### LCS (Longest Common Subsequence)

**구현**:
- 정답과 예측을 어절 단위로 분리
- LCS 알고리즘으로 공통 어절 찾기
- TP = LCS 길이, FP/FN 계산

**특징**:
- 순서 중요 (단어 순서가 바뀌면 FP/FN 증가)
- 부분 매칭 (일부만 맞아도 TP 카운트)

### 리더보드 분할

```
Public LB:  40% (대회 중 공개)
Private LB: 60% (종료 후 공개)
```

**전략적 의미**:
- Public 성능만 보고 최적화 → Private 하락 위험
- 일반화 능력이 핵심
- Train 성능 ≠ Test 성능 (격차 20%p 발견)

---

## 제출 형식

### submission.csv

```csv
id,err_sentence,cor_sentence
grm123456,"오류 문장","교정한 문장"
grm789012,"다른 오류","다른 교정"
...
```

**규칙**:
- 3개 컬럼 필수 (id, err_sentence, cor_sentence)
- err_sentence는 test.csv와 동일해야 함
- cor_sentence만 프롬프트로 생성

### 제출 방법

1. 프롬프트 실험 실행
```bash
uv run python scripts/run_experiment.py --prompt baseline
```

2. Test 제출 파일 확인
```bash
ls outputs/submissions/test/submission_baseline_test.csv
```

3. 리더보드 업로드
- 웹사이트 또는 API로 제출
- 일일 20회 제한

---

## 대회 전략

### 성공 요인

1. **일반화 능력**
   - Train 과적합 방지
   - 다양한 오류 유형 균등 처리
   - 보수적보다 공격적 교정 (Recall 우선)

2. **Few-shot 설계**
   - 1-2개 예시가 적정
   - 각 예시에 다양한 오류 포함
   - 길이/복잡도 균형

3. **출력 형식 제약**
   - 메타데이터 출력 방지
   - 깔끔한 교정 문장만
   - 후처리 규칙 적용

### 실패 함정

1. **Train 성능 맹신**
   - Train Recall 향상 ≠ Test Recall 향상
   - 모든 실험에서 Train↑ → Test↓ 패턴 발견
   - 실제 LB 제출만이 진실

2. **예시 과다**
   - Few-shot 4개 → 27.66% (참패)
   - 과적합, 길이 폭발, 특정 패턴 편향
   - 1개가 최적점

3. **특화 전략**
   - 조사 특화 → Private 11.54% (최저)
   - 단일 유형 강화 → 다른 유형 약화
   - 일반화 > 특화

4. **규칙 기반**
   - Train 분석 → 규칙 추출 → 적용 0개
   - Baseline이 이미 모든 명확한 규칙 처리
   - 진짜 한계는 맥락 이해

---

## 대회 규칙 요약

### 가능한 것

- [완료] 프롬프트 엔지니어링 (System/User message, Few-shot)
- [완료] Train 데이터 기반 RAG
- [완료] 후처리 (메타데이터 제거, 규칙 기반)
- [완료] 다양한 프롬프트 변형 실험

### 불가능한 것

- [실패] 모델 파인튜닝
- [실패] 외부 데이터 사용
- [실패] 모델 변경 (Solar Pro 2 고정)
- [실패] 세션 토큰 2000 초과
- [실패] API 호출 4회 이상/케이스
- [실패] 일일 제출 20회 초과

---

## 최종 결과

### 사용 제출

| 순위 | 프롬프트 | Public | Private | 판정 |
|------|----------|--------|---------|------|
| 1위 1위 | **Baseline** | **34.04** | **13.45** | [완료] **최종** |
| 2위 2위 | Zero-shot | 31.91 | 12.61 | [주의] 보수적 |
| 2위 | 조사 | 31.91 | 11.54 | [실패] Private 최저 |
| 3위 3위 | Plus3 | 27.66 | 9.77 | [실패] 과적합 |

**제출 사용**: 4회 / 20회 (16회 남음)

### Public/Private 격차

```
모든 실험에서 일관되게 약 20%p 격차:
Baseline: 34.04% → 13.45% (-20.59%p)
Zero-shot: 31.91% → 12.61% (-19.30%p)
Plus3: 27.66% → 9.77% (-17.89%p)
```

**원인 추정**:
- 데이터 분포 차이 (Public vs Private)
- Train 데이터가 Public 치우침
- 구조적 문제 (프롬프트로 해결 불가)

---

## 참고 자료

### 공식 문서

- 대회 페이지: [링크]
- Upstage API: https://console.upstage.ai/docs
- 평가 방식: [링크]

### 프로젝트 문서

- 실험 인사이트: [02_EXPERIMENT_INSIGHTS.md](./02_EXPERIMENT_INSIGHTS.md)
- 기술 상세: [03_TECHNICAL_DETAILS.md](./03_TECHNICAL_DETAILS.md)
- 시작 가이드: [01_GETTING_STARTED.md](./01_GETTING_STARTED.md)

---

**작성일**: 2025-10-24
**대상**: 대회 참가자 및 프로젝트 이해
