# 평가 방법 (Evaluation Metrics)

본 대회는 문장 교정(문법/맞춤법 교정) 품질을 정량적으로 평가합니다.

---

## 평가 개요

**입력:** 오탈자가 포함된 문장  
**출력:** 교정된 문장  
**비교:** 정답(test set)과 예측(submission) 비교  
**단위:** 토큰(공백 기준 분할) 단위 비교

---

## 핵심 평가 지표

### 🎯 Recall (재현율)

**리더보드 순위 결정 지표**

$$Recall = \frac{TP}{TP + FP + FN} \times 100$$

- 높을수록 좋음 (최대 100%)
- "실제 오류 중 얼마나 찾았는가"를 측정
- 놓친 오류(FN)를 최소화하는 것이 핵심

---

## 평가 프로세스

### 1단계: 토큰화
```python
# 예시: 공백 기준 분할
원문 = "감자기 침대에서 일어났다"
토큰 = ["감자기", "침대에서", "일어났다"]

정답 = "갑자기 침대에서 일어났다"
정답_토큰 = ["갑자기", "침대에서", "일어났다"]

예측 = "갑자기 침대에 일어났다"
예측_토큰 = ["갑자기", "침대에", "일어났다"]
```

### 2단계: LCS 알고리즘으로 비교

**LCS (Longest Common Subsequence):**
- 정답과 예측의 최장 공통 부분 수열 찾기
- 어떤 부분이 일치하고 다른지 정밀 판별
```
정답: ["갑자기", "침대에서", "일어났다"]
예측: ["갑자기", "침대에",   "일어났다"]
LCS:  ["갑자기",            "일어났다"]  # 공통 부분
```

### 3단계: 평가 항목 계산

| 항목 | 약어 | 설명 | 위 예시 |
|------|------|------|---------|
| True Positive | TP | 정답과 예측이 일치한 교정 | "감자기"→"갑자기" (O) |
| False Positive | FP | 예측이 잘못 수정 | - |
| False Negative | FN | 정답에 있지만 예측이 놓침 | "침대에서" 못 찾음 |
| False Redundant | FR | 불필요하게 수정 | "침대에서"→"침대에" |

---

## 평가 공식

### Recall (재현율) - 순위 결정 지표
```
Recall = TP / (TP + FP + FN) × 100
```

**의미:** 실제 오류 중 몇 %를 찾았는가  
**목표:** 최대화 (100%에 가까울수록 좋음)  
**전략:** False Negative(FN) 최소화

### Precision (정밀도) - 참고용
```
Precision = TP / (TP + FP + FR) × 100
```

**의미:** 찾은 것 중 실제 오류가 몇 %인가  
**참고:** 순위에는 영향 없음

---

## 예시

### Case 1: 완벽한 교정
```
원문:   "감자기 침대에서 일어났다"
정답:   "갑자기 침대에서 일어났다"
예측:   "갑자기 침대에서 일어났다"

TP = 1, FP = 0, FN = 0, FR = 0
Recall = 1 / (1 + 0 + 0) × 100 = 100%
```

### Case 2: 일부 놓침
```
원문:   "감자기 침대에서 일어났다"
정답:   "갑자기 침대에서 일어났다"
예측:   "감자기 침대에서 일어났다"  (교정 안함)

TP = 0, FP = 0, FN = 1, FR = 0
Recall = 0 / (0 + 0 + 1) × 100 = 0%
```

### Case 3: 잘못된 교정
```
원문:   "감자기 침대에서 일어났다"
정답:   "갑자기 침대에서 일어났다"
예측:   "갑자기 침대에 일어났다"  (침대에서→침대에, 오교정)

TP = 1, FP = 1, FN = 0, FR = 1
Recall = 1 / (1 + 1 + 0) × 100 = 50%
```

---

## 리더보드 순위

### Public Leaderboard (대회 중)
- 테스트 데이터의 40% 평가
- 실시간 피드백 제공
- Recall 점수 기준 순위

### Private Leaderboard (대회 종료 후)
- 테스트 데이터의 60% 평가
- **최종 순위 결정**
- Recall 점수 기준 순위

**주의:** Public 점수가 높아도 Private에서 순위가 바뀔 수 있음 (과적합 주의)

---

## Recall 최적화 전략

### ✅ DO (해야 할 것)

1. **보수적 접근 < 적극적 접근**
   - 놓치는 것(FN)이 가장 큰 패널티
   - 의심스러우면 교정하는 것이 유리

2. **오류 유형별 패턴 학습**
   - 조사오류, 맞춤법, 단순오탈자 등
   - 각 유형별 특징 파악

3. **다단계 검증**
   - 1차 교정 + 2차 재검토
   - `calls_per_case=2-3` 활용

### ❌ DON'T (피해야 할 것)

1. **과도한 보수성**
   - "확실한 것만 교정" → FN 증가 → Recall 하락

2. **원문 그대로 출력**
   - 최악의 경우: Recall = 0%

3. **의미 변경**
   - 오류 아닌 부분까지 수정 → FP/FR 증가

---

## 평가 도구

### Python 예시 (참고용)
```python
def calculate_recall(true_tokens, pred_tokens):
    """
    Recall 계산 함수 (간단 버전)
    
    Parameters:
    -----------
    true_tokens : list
        정답 토큰 리스트
    pred_tokens : list
        예측 토큰 리스트
    
    Returns:
    --------
    recall : float
        Recall 점수 (0-100)
    """
    # LCS 알고리즘으로 TP, FP, FN 계산
    # (실제 구현은 더 복잡함)
    
    tp = len(set(true_tokens) & set(pred_tokens))  # 교집합
    fn = len(set(true_tokens) - set(pred_tokens))  # 정답에만 있음
    fp = len(set(pred_tokens) - set(true_tokens))  # 예측에만 있음
    
    if tp + fp + fn == 0:
        return 100.0
    
    recall = (tp / (tp + fp + fn)) * 100
    return recall
```

---

## 참고 자료

- **LCS 알고리즘:** https://ko.wikipedia.org/wiki/최장_공통_부분_수열
- **Precision/Recall 개념:** https://en.wikipedia.org/wiki/Precision_and_recall

---

## 체크리스트

제출 전 확인사항:

- [ ] 모든 문장에 대해 교정 시도했는가?
- [ ] 원문 그대로 제출한 케이스는 없는가?
- [ ] 의심스러운 부분도 적극적으로 교정했는가?
- [ ] 다단계 검증을 수행했는가?
- [ ] Public 점수만 보고 과적합하지 않았는가?

---

**평가 기준:** Recall (재현율)  
**최적화 목표:** False Negative(FN) 최소화  
**전략:** 적극적 교정 + 다단계 검증