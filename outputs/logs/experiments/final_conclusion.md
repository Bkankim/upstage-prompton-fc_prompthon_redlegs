# 최종 결론: Few-shot v2 과적합 확정

**분석 완료 일시:** 2025-10-23  
**최종 검증:** Clean 버전 LB 제출 결과 확인 완료

---

## 결론: **Few-shot v2는 명백한 과적합입니다.**

Clean 버전 제출 결과로 **완전히 확정**되었습니다.

---

## Clean 버전 LB 제출 결과

### Recall: **변화 없음**

| 프롬프트 | 원본 LB | Clean LB | 변화 |
|---------|---------|----------|------|
| **Baseline** | 34.04% | 34.04% | **0.00%p** |
| **Few-shot v2** | 31.91% | 31.91% | **0.00%p** |

### Precision: 소폭 상승

| 프롬프트 | 원본 LB | Clean LB | 변화 |
|---------|---------|----------|------|
| **Baseline** | 13.22% | 13.45% | +0.22%p |
| **Few-shot v2** | 10.79% | 11.28% | +0.49%p |

---

## 핵심 발견 3가지

### 1. Recall은 전혀 변하지 않았다
- 형식 오류(태그, 설명)는 **TP/FN에 영향을 주지 않음**
- 즉, 오류 검출 능력과는 무관
- **과적합 분석이 정확했음을 입증**

### 2. Precision만 소폭 상승
- 형식 오류가 일부 **FP로 잘못 계산**되었음
- 하지만 영향은 미미 (0.2~0.5%p)
- **형식 오류는 부수적 요인일 뿐**

### 3. Baseline vs Few-shot v2 격차 유지
- Clean 후에도 **Baseline이 2.13%p 우수**
- Few-shot v2의 LB 성능 하락은 **진짜 과적합**
- 형식 오류 제거로 해결되지 않음

---

## 최종 성능 비교표

| 지표 | Baseline | Few-shot v2 | 차이 |
|-----|----------|-------------|------|
| **Train Recall** | 32.24% | 35.92% | +3.68%p ✓ |
| **LB Recall (원본)** | 34.04% | 31.91% | -2.13%p |
| **LB Recall (Clean)** | 34.04% | 31.91% | -2.13%p |
| **Train → LB 변화** | **+1.80%p** | **-4.01%p** | **-5.81%p** |

---

## 과적합 확정 근거 (5개 증거)

### 증거 1: Train 성능 향상은 진짜
- Clean 버전 재평가: 35.92% vs 32.24% (+3.68%p)
- 형식 오류 제거 후에도 동일
- ✓ **Train에서 Few-shot v2가 우수함**

### 증거 2: LB 성능 하락도 진짜
- Clean 버전 제출: 31.91% (변화 없음)
- 형식 오류 제거해도 여전히 Baseline보다 낮음
- ✓ **LB에서 Few-shot v2가 열등함**

### 증거 3: Train/LB 격차 5.81%p
- Baseline: +1.80%p (일반화 우수)
- Few-shot v2: -4.01%p (과적합)
- ✓ **명백한 과적합 패턴**

### 증거 4: 형식 오류는 부수적
- Recall 변화: 0%
- Precision 변화: 0.2~0.5%p
- ✓ **형식 오류는 주요 원인 아님**

### 증거 5: 오류 유형 편향
- Few-shot 예시가 Train 상위 3개 유형(52%)만 커버
- 예시 없는 오류 유형(문장부호) 악화 (-4.11%p)
- ✓ **Train 특화 학습 확인**

---

## 과적합 원인 (확정)

### 1. 편향된 예시 선택
- Train 데이터의 상위 오류 유형(조사, 사이시옷, 표준어)에만 집중
- Test 데이터는 다른 오류 분포를 가짐 (추정)

### 2. Few-shot 부작용
- **예시 있는 오류**: 개선 (조사 +3.03%p, 표준어 +8.18%p, 사이시옷 +5.69%p)
- **예시 없는 오류**: 악화 (문장부호 -4.11%p)
- 일반화 능력 저하

### 3. 구체적 예시의 한계
- Train 패턴에 특화
- Test의 새로운 패턴 처리 실패

---

## 형식 오류의 영향 (최종 평가)

### Recall에 미친 영향
- **0% (무영향)**
- 형식 오류는 TP/FN 판단과 무관
- Recall 차이는 순수하게 과적합 효과

### Precision에 미친 영향
- **0.2~0.5%p (미미)**
- 형식 오류가 일부 FP로 계산됨
- 전체 성능 차이의 부수적 요인

### 결론
**형식 오류는 과적합의 주요 원인이 아님**

---

## 현재 최고 프롬프트

### **Baseline (LB 34.04%)**

**장점:**
- 일반적 접근 (구체적 예시 없음)
- 보수적 교정 (확실한 오류만)
- 안정적 일반화 (Train/LB +1.80%p)

**단점:**
- Train 성능이 Few-shot v2보다 낮음
- 개선 여지 존재

---

## 다음 전략 (확정)

### 우선순위 1: Chain-of-Thought (CoT) 프롬프트

**근거:**
- Few-shot 방식의 한계 확인
- 일반화 능력이 핵심
- 예시 대신 추론 과정 제시

**목표:**
- Baseline 34.04% 돌파
- 과적합 방지
- 모든 오류 유형 균등 처리

**접근:**
```
1단계: 오류 탐지 (문장 분석)
2단계: 오류 분류 (유형 판단)
3단계: 교정 실행 (올바른 표현)
4단계: 검증 (자연스러움 확인)
```

### 피해야 할 것

1. Train 데이터 기반 Few-shot 예시
2. 특정 오류 유형에 편향된 접근
3. 구체적 예시에 과도한 의존
4. Test 데이터 분포 무시

---

## 교훈

### 배운 점

1. **Train 성능 ≠ LB 성능**
   - Few-shot v2가 Train에서 3.68%p 우수했지만 LB에서 2.13%p 열등

2. **일반화 > 최적화**
   - Baseline의 일반성이 Few-shot v2의 최적화보다 우수

3. **Few-shot은 양날의 검**
   - 특정 유형 개선, 다른 유형 악화
   - 전체적으로 역효과

4. **형식 오류의 영향은 미미**
   - Recall에 무영향
   - Precision에만 0.2~0.5%p

5. **Train/LB 격차가 명확한 지표**
   - +1.80%p (일반화 우수) vs -4.01%p (과적합)

### 피해야 할 것

1. Train 데이터에만 맞춘 최적화
2. 편향된 예시 선택
3. 구체적 예시에 과도한 의존
4. 형식 오류에 과도한 집중 (부수적 요인)

---

## 통계 요약

### 실험 진행 내역
- 총 프롬프트: 3개 (Baseline, Few-shot v2, Error Types v3)
- LB 제출: 6회 (원본 2개 + Clean 2개 + Error Types v3 2개)
- 남은 제출 횟수: 14회 / 20회

### 성능 범위
- 최고 LB: Baseline 34.04%
- 최저 LB: Few-shot v2 31.91%
- Train 최고: Few-shot v2 35.92%
- Train 최저: Baseline 32.24%

### 목표까지 거리
- 현재 최고: 34.04%
- 목표: 75%
- 격차: **40.96%p** 개선 필요

---

## 최종 권고

### 즉시 행동
1. ✓ Baseline 계속 사용 (현재 최고)
2. ✗ Few-shot v2 폐기 (과적합 확정)
3. ✗ Error Types v3 폐기 (형식 오류 + 성능 낮음)

### 다음 실험
**Chain-of-Thought 프롬프트 개발 (Task 2.3)**
- 예시 없이 추론 과정으로 접근
- 일반화 능력 극대화
- 과적합 방지

---

**End of Analysis**

**결론: Few-shot v2는 명백한 과적합. Baseline 유지하고 CoT 프롬프트 개발 진행.**
