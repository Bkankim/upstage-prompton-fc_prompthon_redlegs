# Few-shot v2 과적합 심층 분석 최종 보고서

**분석 일시:** 2025-10-23  
**분석자:** Deep Analysis System

---

## 요약

**결론: Few-shot v2는 Train 데이터에 과적합되었으며, Train 성능 향상은 진짜였지만 LB에서는 역효과 발생**

| 지표 | Baseline | Few-shot v2 | 차이 |
|-----|----------|-------------|------|
| **Train Recall** | 32.24% | 35.92% | +3.68%p |
| **LB Recall** | 34.04% | 31.91% | -2.13%p |
| **Train → LB 변화** | +1.80%p | **-4.01%p** | **-5.81%p gap** |

---

## 1. Train 성능 재검증

### 1.1 출력 형식 문제 발견

두 프롬프트 모두 출력 형식 오류 존재:
- **Baseline**: 25개 (9.8%)가 `<교정>` 태그 또는 설명 포함
- **Few-shot v2**: 22개 (8.7%)가 `<교정>` 태그 또는 설명 포함

### 1.2 Clean 버전 재평가 결과

형식 문제 제거 후 재평가:

| 프롬프트 | 원본 Recall | Clean Recall | 원본 Precision | Clean Precision |
|---------|------------|--------------|---------------|----------------|
| Baseline | 32.24% | **32.24%** | 14.08% | 14.31% (+0.23%p) |
| Few-shot v2 | 35.92% | **35.92%** | 16.86% | 17.05% (+0.19%p) |

**결론: Train 성능 차이는 진짜였음 (Few-shot v2 35.92% vs Baseline 32.24%, +3.68%p)**

---

## 2. 오류 유형별 성능 분석

### 2.1 Few-shot v2가 크게 개선한 오류 유형 (>2%p)

| 오류 유형 | Baseline | Few-shot v2 | 차이 | Few-shot 예시 |
|----------|----------|-------------|------|--------------|
| 문법-품사에따른활용 | 18.75% | 33.33% | **+14.58%p** | ✓ 있음 |
| 맞춤법 | 53.85% | 66.67% | **+12.82%p** | ✗ 없음 |
| 표준어비표준어 | 14.04% | 22.22% | **+8.18%p** | ✓ 있음 |
| 사이시옷 | 13.46% | 19.15% | **+5.69%p** | ✓ 있음 |
| 받침에따른 | 9.09% | 14.29% | **+5.20%p** | ✗ 없음 |
| 조사오류 | 12.90% | 15.93% | **+3.03%p** | ✓ 있음 |

### 2.2 Few-shot v2가 악화한 오류 유형

| 오류 유형 | Baseline | Few-shot v2 | 차이 | Few-shot 예시 |
|----------|----------|-------------|------|--------------|
| 문장부호 | 13.79% | 9.68% | **-4.11%p** | ✗ 없음 |

---

## 3. Few-shot 예시 분석

### 3.1 Few-shot v2의 6개 예시

1. **조사오류** (2개): "그 모습은" → "그 모습이"
2. **표준어비표준어** (1개): "눈 깜빡할" → "눈 깜짝할"
3. **사이시옷** (1개): "뒤머리" → "뒷머리"
4. **능동피동** (1개): "부딪쳐서" → "부딪혀서"
5. **문법(연결어미)** (1개): "답답하자" → "답답해서"

### 3.2 Train 데이터 오류 분포

**상위 5개 오류 유형:**

1. **조사오류** (41개, 16.1%) - ✓ 예시 있음
2. **사이시옷** (34개, 13.4%) - ✓ 예시 있음
3. **표준어비표준어** (24개, 9.4%) - ✓ 예시 있음
4. **어휘관련오류** (22개, 8.7%) - ✗ 예시 없음
5. **단위** (20개, 7.9%) - ✗ 예시 없음

**Few-shot 커버리지:**
- 커버한 오류: 132개 (52.0%)
- 커버 안 된 오류: 122개 (48.0%)

### 3.3 예시 선택 전략의 효과

✓ **성공**: 상위 3개 오류 유형 (38.9%)을 모두 커버  
✓ **성공**: 예시가 있는 오류 유형은 모두 개선  
✗ **실패**: 예시가 없는 "문장부호"는 악화 (-4.11%p)  
✗ **실패**: LB에서 전체 성능 하락

---

## 4. 과적합 원인 분석

### 4.1 확인된 과적합 증거

1. **Train → LB 성능 역전**
   - Baseline: 32.24% → 34.04% (+1.80%p, 일반화 우수)
   - Few-shot v2: 35.92% → 31.91% (-4.01%p, 과적합)

2. **Train 특화 학습**
   - Few-shot 예시가 Train 상위 3개 오류 유형에 집중
   - 52%만 커버하면서 나머지 48%는 무시

3. **LB 역효과**
   - Train에서 +3.68%p 향상했지만
   - LB에서 -2.13%p 하락
   - **총 5.81%p 격차**

### 4.2 과적합이 발생한 이유

#### 원인 1: 편향된 예시 선택
- Train 데이터의 상위 오류 유형에만 집중
- Test 데이터는 다른 오류 분포를 가질 가능성

#### 원인 2: Few-shot 부작용
- 예시가 있는 오류에만 과도하게 집중
- 예시가 없는 오류 유형 (문장부호, 어휘, 단위 등) 처리 능력 하락

#### 원인 3: 구체적 예시의 양날의 검
- **장점**: 특정 패턴 인식 능력 향상
- **단점**: 예시와 다른 패턴을 만나면 처리 못함

---

## 5. Baseline이 LB에서 우수한 이유

### 5.1 Baseline의 장점

1. **일반적 접근**: 구체적 예시 없이 일반 원칙만 제시
2. **보수적 교정**: 확실한 오류만 교정 (불필요한 교정 방지)
3. **안정적 일반화**: Train/LB 격차 1.80%p (Few-shot v2는 -4.01%p)

### 5.2 성능 비교

```
Train 성능: Few-shot v2 > Baseline (35.92% vs 32.24%, +3.68%p)
LB 성능:    Baseline > Few-shot v2 (34.04% vs 31.91%, +2.13%p)
```

**결론: Baseline이 현재 최고 프롬프트**

---

## 6. 과적합이 맞는가?

### YES - 다음 증거로 확인됨:

1. ✓ **Train 성능 향상은 진짜** (35.92% vs 32.24%)
2. ✓ **LB에서 성능 하락** (31.91% vs 34.04%)
3. ✓ **Train 특화 학습** (상위 3개 오류 유형에 집중)
4. ✓ **일반화 실패** (Baseline보다 5.81%p 격차)
5. ✓ **예시 없는 오류 유형 악화** (문장부호 -4.11%p)

### 과적합 vs 평가 오류 vs 데이터 분포 차이

| 가설 | 증거 | 결론 |
|-----|-----|------|
| **평가 오류** | Train 재평가 결과 동일 | ✗ 해당 없음 |
| **데이터 분포 차이** | 매우 가능성 높음 | ✓ 일부 원인 |
| **과적합** | 모든 증거 일치 | ✓ **주요 원인** |

---

## 7. 해결 방안

### 7.1 단기 전략 (즉시 적용 가능)

#### Option A: Baseline 사용 (추천)
- **장점**: 현재 최고 LB 성능 (34.04%)
- **장점**: 안정적 일반화
- **단점**: Train 성능이 Few-shot v2보다 낮음

#### Option B: Few-shot v2 폐기
- Train 성능이 좋아도 LB에서 나쁘면 무의미
- 과적합된 프롬프트 사용 중단

### 7.2 중기 전략 (새로운 접근)

#### Strategy 1: Few-shot v4 (개선된 버전)
- 모든 오류 유형을 균등하게 커버
- 20개 오류 유형 각각 1개씩 예시 추가
- 예상 효과: 일반화 향상, Train/LB 격차 감소

#### Strategy 2: Chain-of-Thought (Task 2.3)
- 예시 대신 추론 과정 제시
- 오류 탐지 → 분류 → 교정 → 검증 단계
- 예상 효과: 일반화 우수, 과적합 방지

#### Strategy 3: Baseline 강화
- Baseline에 최소한의 힌트만 추가
- 조사 오류, 사이시옷 등 약점 보완
- 예상 효과: 안정적이지만 점진적 향상

#### Strategy 4: 하이브리드 접근
- Baseline의 일반성 + Few-shot의 구체성
- 각 오류 유형별 간단한 가이드라인만 제시
- 구체적 예시는 최소화

### 7.3 장기 전략 (근본 해결)

#### 1. 데이터 증강
- Train 데이터의 오류 분포를 다양화
- 부족한 오류 유형 (문장부호, 어휘 등) 보강

#### 2. 앙상블
- Baseline + Few-shot v4 + CoT 결과 조합
- 각각의 장점 활용

#### 3. 적응적 Few-shot
- 입력 문장의 오류 유형을 먼저 판단
- 해당 유형의 예시만 선택적으로 제시

---

## 8. 권장 사항

### 즉시 행동:

1. **Baseline LB 제출 유지** (현재 최고 성능)
2. **Few-shot v2 폐기** (과적합 확인)
3. **Chain-of-Thought 프롬프트 개발** (Task 2.3)

### 다음 실험:

#### 우선순위 1: Chain-of-Thought (CoT)
- 일반화 능력이 가장 중요
- 예시 없이 추론 과정으로 접근
- 목표: Baseline 34.04% 돌파

#### 우선순위 2: Baseline 강화
- 안정적인 베이스에서 점진적 개선
- 위험이 낮고 예측 가능

#### 우선순위 3: Few-shot v4 (신중)
- 모든 오류 유형 균등 커버
- 다시 과적합될 위험 있음

---

## 9. 교훈

### 배운 점:

1. **Train 성능이 좋다고 LB 성능이 좋은 것은 아니다**
2. **Few-shot 예시는 양날의 검** (개선과 악화 동시 발생)
3. **일반화가 핵심** (Baseline이 Few-shot v2보다 우수한 이유)
4. **오류 분포를 고려한 예시 선택 필요**
5. **Train/LB 격차가 과적합의 명확한 지표**

### 피해야 할 것:

1. Train 데이터에만 맞춘 최적화
2. 편향된 예시 선택
3. 구체적 예시에 과도한 의존
4. Test 데이터 분포 무시

---

## 10. 결론

**Few-shot v2는 명백한 과적합 케이스입니다.**

- ✓ Train 성능 향상 (35.92%)은 진짜였음
- ✓ LB 성능 하락 (31.91%)도 진짜임
- ✓ 과적합 원인: Train 상위 오류 유형에 특화된 예시 선택
- ✓ 해결 방안: Chain-of-Thought 또는 Baseline 강화

**현재 최고 프롬프트: Baseline (LB 34.04%)**

**다음 목표: CoT 프롬프트로 35% 돌파 후 40% 향해 진행**

---

**End of Report**
