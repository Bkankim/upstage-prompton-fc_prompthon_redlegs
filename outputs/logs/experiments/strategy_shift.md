# 전략 전환: Train 최적화 → 일반화 중심

**결론 도출 일시:** 2025-10-23  
**근거:** Few-shot v2 과적합 분석 완료

---

## 핵심 인사이트

> **"Train 성능을 높이는 것이 LB 성능을 높이는 것이 아니다"**

### 실험 결과가 증명한 것

| 접근 방식 | Train | LB | 일반화 | 결과 |
|----------|-------|-----|--------|------|
| **Train 최적화** (Few-shot v2) | 35.92% ✓ | 31.91% ✗ | -4.01%p | **실패** |
| **일반화 중심** (Baseline) | 32.24% | 34.04% ✓ | +1.80%p | **성공** |

**결론: 일반화가 핵심이다**

---

## 왜 일반화가 중요한가?

### 1. Test 데이터 분포를 알 수 없다
- Train: 조사(16.1%), 사이시옷(13.4%), 표준어(9.4%)
- Test: **알 수 없음**
- Few-shot v2는 Train 분포에 맞췄다가 실패

### 2. 구체적 예시는 과적합 위험
- 예시 있는 오류: 개선
- 예시 없는 오류: 악화
- **전체적으로 역효과**

### 3. Train/LB 격차가 성능을 결정
```
격차 +1.80%p (Baseline) → LB 34.04% (1등)
격차 -4.01%p (Few-shot v2) → LB 31.91% (2등)
```

---

## 전략 전환

### Before: Train 최적화 접근 ✗

**목표:**
- Train 데이터에서 최고 성능
- Few-shot 예시로 Train 패턴 학습
- 오류 유형별 맞춤 전략

**결과:**
- Train 35.92% 달성 ✓
- LB 31.91% 하락 ✗
- **과적합 발생**

**문제점:**
1. Train 분포에 편향
2. Test 분포 무시
3. 구체적 예시의 한계
4. 일반화 능력 저하

---

### After: 일반화 중심 접근 ✓

**목표:**
- **모든 데이터에서 안정적 성능**
- 일반적 원칙과 추론 과정
- 균형잡힌 오류 처리

**기대 결과:**
- Train 성능: 적당히 유지
- LB 성능: **안정적 상승**
- Train/LB 격차: 최소화

**핵심 원칙:**
1. 일반적 접근 (구체적 예시 최소화)
2. 추론 과정 명시 (Chain-of-Thought)
3. 모든 오류 유형 균등 처리
4. 보수적 교정 (확실한 오류만)

---

## Robust 프롬프팅 전략

### 1. Chain-of-Thought (CoT) 접근

**핵심 아이디어:**
- 예시 대신 **추론 과정** 제시
- 모델이 스스로 생각하도록 유도
- 일반화 능력 극대화

**구조:**
```
1단계: 문장 읽기 및 분석
  → "이 문장에서 어색한 부분이 있는가?"

2단계: 오류 탐지
  → "어떤 부분이 잘못되었는가?"

3단계: 오류 분류
  → "이것은 어떤 종류의 오류인가?"

4단계: 교정 실행
  → "올바른 표현은 무엇인가?"

5단계: 검증
  → "교정된 문장이 자연스러운가?"
```

**장점:**
- ✓ Train 분포에 독립적
- ✓ 모든 오류 유형 처리 가능
- ✓ 과적합 위험 낮음
- ✓ 일반화 능력 우수

---

### 2. 최소한의 가이드라인만 제공

**나쁜 예 (구체적 예시):**
```
조사 오류: "그 모습은" → "그 모습이"
표준어: "눈 깜빡할" → "눈 깜짝할"
```
→ Train 패턴에 과적합

**좋은 예 (일반적 원칙):**
```
- 조사는 문맥에 맞게 선택하세요
- 표준어를 사용하세요
- 문장이 자연스러워야 합니다
```
→ 모든 경우에 적용 가능

---

### 3. 균형잡힌 오류 처리

**Few-shot v2의 문제:**
- 조사, 사이시옷, 표준어: 집중 (52%)
- 문장부호, 어휘, 단위: 무시 (48%)

**Robust 접근:**
- 20개 오류 유형 **균등하게** 처리
- 특정 유형에 편향 금지
- 보편적 교정 원칙 적용

---

### 4. 보수적 교정 원칙

**핵심:**
- **확실한 오류만** 교정
- 의심스러우면 그대로 둠
- False Positive 최소화

**Baseline이 성공한 이유:**
```
Baseline: 
  - 일반적 지시
  - 보수적 접근
  → LB 34.04% (1등)

Few-shot v2:
  - 구체적 예시
  - 적극적 교정
  → LB 31.91% (2등)
```

---

## 구체적 실행 계획

### Phase 1: Chain-of-Thought 프롬프트 (Task 2.3)

**목표:**
- Baseline 34.04% 돌파
- 일반화 능력 극대화

**설계 원칙:**
1. 예시 없음 (또는 극소수)
2. 추론 과정 명시
3. 모든 오류 유형 언급
4. 보수적 교정 강조

**예상 성능:**
- Train: 33~34% (Baseline 수준)
- LB: 35~37% (Baseline 초과 기대)
- Train/LB 격차: +1~3%p (일반화 우수)

---

### Phase 2: Baseline 강화

**접근:**
- Baseline에 최소한의 힌트만 추가
- 일반성 유지하면서 약점 보완

**개선 방향:**
1. 조사 오류 처리 힌트
2. 사이시옷 규칙 간단 언급
3. 표준어 사용 강조

**예상 효과:**
- 안정적이지만 점진적 개선
- 과적합 위험 낮음

---

### Phase 3: 하이브리드 접근 (신중)

**아이디어:**
- CoT의 일반성 + 최소한의 예시

**예시 선택 기준:**
1. 모든 오류 유형 커버 (20개)
2. 각 유형당 1개만
3. 가장 일반적인 패턴만

**위험:**
- 다시 과적합될 가능성
- 신중하게 접근

---

## 피해야 할 것

### ✗ Train 데이터 기반 최적화
- Train 분포에 맞춘 예시
- Train 상위 오류 유형 집중
- Train 성능만 추구

### ✗ 구체적 예시 의존
- 특정 패턴 암기
- 예시와 다른 케이스 처리 실패

### ✗ 편향된 접근
- 일부 오류 유형만 집중
- 다른 유형 무시

### ✗ 공격적 교정
- 의심스러운 부분까지 교정
- FP 증가

---

## 성공 지표

### 좋은 프롬프트의 특징

1. **Train/LB 격차 작음**
   - 이상적: +0~2%p
   - 좋음: +2~4%p
   - 나쁨: -2%p 이하 (과적합)

2. **LB 성능 우수**
   - 목표: 35%+ (현재 최고 34.04%)
   - 최종 목표: 75%

3. **안정성**
   - 여러 제출에서 일관된 성능
   - 큰 변동 없음

---

## 예상 결과

### 시나리오 1: CoT 성공 (60% 확률)
```
CoT Train: 33%
CoT LB: 36%
격차: +3%p
```
→ Baseline 초과, 일반화 우수  
→ **전략 성공**

### 시나리오 2: CoT 실패 (30% 확률)
```
CoT Train: 30%
CoT LB: 31%
격차: +1%p
```
→ Baseline보다 낮지만 일반화는 좋음  
→ Baseline 강화로 전환

### 시나리오 3: 예상 외 (10% 확률)
```
CoT Train: 38%
CoT LB: 32%
격차: -6%p
```
→ 또 과적합  
→ 근본적 재검토 필요

---

## 최종 목표

### 단기 (1~2일)
- CoT 프롬프트로 Baseline 34.04% 돌파
- LB 35~37% 달성

### 중기 (3~5일)
- 여러 robust 접근 실험
- LB 40% 돌파

### 장기 (대회 종료까지)
- 최적 일반화 전략 확립
- LB 50%+ 달성
- (최종 목표 75%는 매우 도전적)

---

## 결론

> **"일반화가 핵심이다. Train 성능은 수단일 뿐, LB 성능이 목표다."**

**전략 전환:**
- ✗ Train 최적화 중심
- ✓ 일반화 중심

**다음 행동:**
1. Chain-of-Thought 프롬프트 개발 (Task 2.3)
2. 일반적 원칙 + 추론 과정
3. 구체적 예시 최소화
4. 보수적 교정

**성공 기준:**
- Train/LB 격차 최소화
- LB 성능 지속적 향상
- 안정적 결과

---

**End of Strategy Document**
