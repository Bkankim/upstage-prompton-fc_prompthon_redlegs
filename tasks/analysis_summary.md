# GEC Promptathon 분석 요약

## 대회 핵심 정보

### 평가 지표
- **Recall (재현율)**: TP/(TP+FP+FN) × 100
- **전략**: False Negative 최소화 (놓치는 오류를 줄이는 것이 최우선)
- **접근법**: 적극적 교정 > 보수적 접근

### 제약 사항
- 세션 토큰: 최대 2000개
- API 호출: 케이스당 최대 3회
- 일일 제출: 20회 제한
- 외부 데이터: 사용 금지

### 데이터 규모
- 학습 데이터: 254개 문장
- 테스트 데이터: 109개 문장 (Public 40%, Private 60%)
- 평균 문장 길이: 136.8자

## 오류 유형 분석

### 주요 오류 분포
1. **조사오류** (16.1%) - 은/는, 이/가, 을/를 등
2. **사이시옷** (13.4%) - 고개짓→고갯짓, 윗층→위층
3. **표준어비표준어** (9.4%) - 아니오→아니요, 깜빡→깜짝
4. **어휘관련오류** (8.7%) - 가름→갈음, 재고→제고
5. **단위** (7.9%) - 단위 표기, 범위 표현
6. **단순오탈자** (7.1%) - 매일→내일, 안녕하십까→안녕하십니까

### 교정 패턴 특징
- 60%는 교정 후 길이 변화 없음
- 25%는 길이 증가, 15%는 길이 감소
- 반복되는 패턴 존재 (넉넉치→넉넉지, 깨끗치→깨끗지)

## 프롬프트 전략

### 1. 기본 전략 (Single-turn)
- 단순 직접 교정
- 최소 토큰 사용
- Temperature: 0.1

### 2. 다단계 검증 (Multi-turn)
- 1차: 오류 탐지
- 2차: 교정 실행
- 3차: 최종 검증 (선택)
- calls_per_case: 2-3 활용

### 3. Chain-of-Thought
- 단계별 추론 과정
- 오류 유형 분석 → 교정 방법 결정 → 최종 출력

### 4. Few-shot Learning
- 오류 유형별 예시 제공
- Train 데이터의 패턴 활용
- 자주 나오는 오류에 집중

### 5. Error-type Specific
- 조사오류 특화 프롬프트
- 사이시옷 규칙 강조
- 표준어 교정 집중

## Recall 최적화 핵심 포인트

### DO (해야 할 것)
1. **의심스러우면 교정** - FN 최소화
2. **오류 유형별 패턴 학습** - 데이터 기반 접근
3. **다단계 검증** - 놓친 오류 재검토
4. **모든 문장 적극 검토** - 원문 그대로 출력 금지

### DON'T (피해야 할 것)
1. **과도한 보수성** - 확실한 것만 교정 X
2. **원문 그대로 출력** - Recall 0% 위험
3. **의미 변경** - FP/FR 증가 주의
4. **Public 과적합** - Private 60% 고려

## 실험 우선순위

1. **우선 실험**
   - 조사오류/사이시옷 특화 프롬프트 (29.5% 커버)
   - Multi-turn 검증 템플릿
   - Temperature 0.1 고정

2. **추가 실험**
   - Few-shot with top 오류 패턴
   - Chain-of-Thought 방식
   - Error-type별 세분화

3. **최적화**
   - 프롬프트 길이 최적화 (토큰 제한)
   - API 호출 전략 (1회 vs 2-3회)
   - 앙상블 전략 검토